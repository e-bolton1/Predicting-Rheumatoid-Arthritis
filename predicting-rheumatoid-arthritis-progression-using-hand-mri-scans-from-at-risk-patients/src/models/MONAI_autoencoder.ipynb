{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Deep Learning Model Training and Evaluation Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This document outlines a comprehensive procedure for training, evaluating, and testing a deep learning model using the SwinUNETR architecture. The workflow includes initialising the dataset and dataloader, setting up the model, training with early stopping, evaluating performance using metrics like SSIM and PSNR, and saving the results for further analysis.\n",
    "\n",
    "### Key Steps:\n",
    "\n",
    "1. **Data Preparation**: Loading and preprocessing the dataset for both training and validation.\n",
    "2. **Model Initialisation**: Setting up the SwinUNETR model architecture and loading pre-trained weights.\n",
    "3. **Training**: Executing the training loop with early stopping and logging the progress.\n",
    "4. **Evaluation**: Running the trained model on validation data to compute key metrics.\n",
    "5. **Testing**: Testing the model on a subset of the validation data and saving the results.\n",
    "6. **Results Saving**: Exporting the performance metrics and model state for future reference and analysis.\n",
    "\n",
    "This pipeline is designed to be modular and flexible, allowing for easy adjustments to hyperparameters, model architecture, and evaluation criteria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries\n",
    "\n",
    "This section imports the necessary libraries for logging, file handling, system operations, and deep learning model development.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install tensorboardX, which is used for logging and visualizing training metrics in TensorBoard\n",
    "!pip install tensorboardX\n",
    "\n",
    "# Install MONAI (Medical Open Network for AI) version 1.3.2 from the conda-forge channel.\n",
    "# MONAI is a framework for developing deep learning models in medical imaging.\n",
    "!conda install -c conda-forge monai=1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for logging, file handling, and system operations\n",
    "import logging  # Provides a flexible framework for emitting log messages from Python programs.\n",
    "import os  # Provides a way of using operating system-dependent functionality, such as reading or writing to the file system.\n",
    "import shutil  # Used for high-level file operations, such as copying or removing files and directories.\n",
    "import sys  # Provides access to some variables used or maintained by the Python interpreter and to functions that interact with the interpreter.\n",
    "import tempfile  # Used to create temporary files and directories.\n",
    "import random  # Implements pseudo-random number generators for various distributions.\n",
    "import numpy as np  # Fundamental package for scientific computing with Python, providing support for large, multi-dimensional arrays and matrices.\n",
    "from tqdm import trange  # Provides a progress bar for loops, making it easier to track long-running tasks.\n",
    "import matplotlib.pyplot as plt  # A plotting library used for creating static, animated, and interactive visualizations in Python.\n",
    "import torch  # PyTorch, an open-source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing.\n",
    "\n",
    "# Importing functions and classes from the MONAI library, a deep learning framework specialized for healthcare imaging\n",
    "from monai.apps import download_and_extract  # Utility to download and extract files, particularly useful for datasets.\n",
    "from monai.apps import download_url\n",
    "from monai.config import print_config  # Prints the current configuration of MONAI, including the environment, installed packages, and versions.\n",
    "from monai.data import CacheDataset, DataLoader  # CacheDataset caches data and is useful for datasets that fit in memory. DataLoader is used to load the data in batches.\n",
    "from monai.networks.nets import AutoEncoder, SwinUNETR  # Importing an AutoEncoder model, which is a type of neural network used for unsupervised learning, particularly for dimensionality reduction.\n",
    "from monai.transforms import (  # Importing various transformations to be applied to the data.\n",
    "    EnsureChannelFirstD,  # Ensures the channel dimension is first in the data tensor.\n",
    "    Compose,  # Allows the chaining of multiple transformations to be applied sequentially.\n",
    "    LoadImageD,  # Loads images from a file.\n",
    "    RandFlipD,  # Randomly flips the image along a specified axis.\n",
    "    RandRotateD,  # Randomly rotates the image within a specified angle range.\n",
    "    RandZoomD,  # Randomly zooms in or out of the image within a specified range.\n",
    "    ScaleIntensityD,  # Scales the intensity of the image to a specified range.\n",
    "    EnsureTypeD,  # Ensures the output is of a specific data type.\n",
    "    Lambda,  # Allows for custom transformations using a lambda function.\n",
    ")\n",
    "from monai.utils import set_determinism  # Sets the seed for random number generators to ensure reproducibility.\n",
    "from monai.networks.utils import copy_model_state  # Utility function for copying the model state.\n",
    "from monai.networks.nets.swin_unetr import filter_swinunetr  # Filters specific layers in the SwinUNETR model.\n",
    "from monai.transforms import RandSpatialCropd  # Randomly crops a portion of the image.\n",
    "\n",
    "from torch.amp import autocast, GradScaler  # Mixed precision training utilities\n",
    "import math  # Provides access to mathematical functions.\n",
    "import warnings  # Used to issue warning messages.\n",
    "from typing import List  # Allows for type hinting, specifying that a variable is a list.\n",
    "\n",
    "from torch import nn as nn  # PyTorch module containing all neural network layers and functions.\n",
    "from torch.optim import Adam, Optimizer  # Adam optimizer and base optimizer class from PyTorch.\n",
    "from torch.optim.lr_scheduler import LambdaLR, _LRScheduler  # Learning rate scheduler and base class for custom schedulers.\n",
    "import glob  # For finding all file paths matching a specified pattern.\n",
    "import pydicom  # For reading, modifying, and writing DICOM files.\n",
    "from tensorboardX import SummaryWriter  # Writes TensorBoard-compatible logs for PyTorch models.\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Print the current MONAI configuration\n",
    "print_config()  # This line will print the MONAI configuration, including environment details and installed packages.\n",
    "\n",
    "import torch.optim as optim  # Optimizer functions from PyTorch.\n",
    "from torch.utils.data import DataLoader  # DataLoader class to load data in batches.\n",
    "from torch.utils.tensorboard import SummaryWriter  # Writes TensorBoard logs, similar to tensorboardX but included in PyTorch.\n",
    "from tqdm import tqdm  # Provides a progress bar for loops, similar to trange.\n",
    "import time  # Provides various time-related functions.\n",
    "import torch.nn.functional as F  # Contains functions used in building neural networks, such as activation functions and loss functions.\n",
    "import psutil  # For memory tracking.\n",
    "import gc  # Python's garbage collection module, used to manually free up memory.\n",
    "from torch.cuda.amp import autocast  # For automatic mixed precision (AMP) in CUDA.\n",
    "import pandas as pd  # For data manipulation and analysis.\n",
    "\n",
    "# Standard library imports\n",
    "from pathlib import Path  # To handle and manipulate filesystem paths.\n",
    "\n",
    "# Third-party imports\n",
    "from PIL import Image  # For opening, manipulating, and saving many different image file formats.\n",
    "\n",
    "# PyTorch-I/O extension\n",
    "import torchio as tio  # For medical image processing in PyTorch.\n",
    "\n",
    "# pydicom imports\n",
    "from pydicom.data import get_testdata_file  # For accessing test DICOM files.\n",
    "from pydicom.fileset import FileSet  # For working with DICOM FileSets.\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split  # For splitting datasets into training and testing sets.\n",
    "\n",
    "from collections import defaultdict  # For creating dictionaries with default values.\n",
    "from monai.transforms import apply_transform  # Applies a transform to data.\n",
    "from tqdm import tqdm\n",
    "from piqa import PSNR, SSIM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # Releases all unused memory cached by the CUDA backend, freeing up GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up basic logging configuration to output log messages to the console (stdout).\n",
    "# The logging level is set to INFO, meaning all messages at this level and above\n",
    "# (INFO, WARNING, ERROR, CRITICAL) will be displayed.\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "\n",
    "# Set deterministic behavior for reproducibility. This is important in experiments where\n",
    "# you want to ensure that the results are the same every time the code is run. \n",
    "# The seed value is set to 0, which will be used to initialize the random number generator.\n",
    "set_determinism(0)\n",
    "\n",
    "# Determine the device to run the computations on. If a CUDA-capable GPU is available,\n",
    "# the device will be set to \"cuda\" (meaning GPU); otherwise, it will fall back to \"cpu\".\n",
    "# This allows the code to take advantage of GPU acceleration if possible.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Transformations for Training and Testing\n",
    "\n",
    "In this section, we define the transformations applied to the training and testing datasets using `RandSpatialCropd`. This function crops a 3D region from the image with specific parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for training and testing datasets\n",
    "# RandSpatialCropd randomly crops a 3D region from the image. \n",
    "# - keys=[\"im\"]: Specifies the key in the dictionary that holds the image data.\n",
    "# - roi_size=(96, 96, 96): Specifies the size of the region of interest (ROI) to be cropped (in 3D dimensions).\n",
    "# - random_center=True: Ensures that the center of the cropped region is selected randomly.\n",
    "# - random_size=False: The size of the cropped region is fixed, not random.\n",
    "\n",
    "train_transforms = RandSpatialCropd(keys=[\"im\"], roi_size=(96, 96, 96), random_center=True, random_size=False)\n",
    "test_transforms = RandSpatialCropd(keys=[\"im\"], roi_size=(96, 96, 96), random_center=True, random_size=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation: Splitting Labels into Training and Validation Sets\n",
    "\n",
    "This section of the code reads label data from a CSV file, splits the data into training and validation sets, and saves these splits as separate CSV files for future reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory and CSV path\n",
    "training_data_dir = r'c:\\Users\\scmmw\\OneDrive - University of Leeds\\t1_vibe_we_hand_subset'\n",
    "csv_path = r'C:\\Users\\scmmw\\OneDrive - University of Leeds\\t1_vibe_we_hand_subset\\training_labels_subset.csv'\n",
    "\n",
    "# Read the labels DataFrame\n",
    "labels_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_df, valid_df = train_test_split(labels_df, test_size=0.2, random_state=42, stratify=labels_df['progression'])\n",
    "\n",
    "# Save the splits for reference (optional)\n",
    "train_df.to_csv(os.path.join(training_data_dir, 'train_split.csv'), index=False)\n",
    "valid_df.to_csv(os.path.join(training_data_dir, 'valid_split.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of full paths for training patient directories.\n",
    "# os.path.join() is used to concatenate the base directory with the patient IDs from the training DataFrame.\n",
    "train_patient_dirs = [os.path.join(training_data_dir, subject_name) for subject_name in train_df['patient ID'].tolist()]\n",
    "\n",
    "# Create a list of full paths for validation patient directories.\n",
    "# os.path.join() is used to concatenate the base directory with the patient IDs from the validation DataFrame.\n",
    "valid_patient_dirs = [os.path.join(training_data_dir, subject_name) for subject_name in valid_df['patient ID'].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HandScanDataset2: Custom PyTorch Dataset Class\n",
    "\n",
    "This section defines the `HandScanDataset2` class, a custom PyTorch `Dataset` for handling and processing hand scan images stored in DICOM format. The class includes methods for loading, transforming, and preparing the data for use in deep learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class HandScanDataset2(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, device=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patient_dirs (list): List of paths to the patient directories.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            device (torch.device, optional): Device to use for tensor operations (e.g., 'cuda' or 'cpu').\n",
    "        \"\"\"\n",
    "        self.data_dir = sorted(data_dir)  # Sort the list of patient directories for consistent ordering.\n",
    "        self.transform = transform  # Store the transform function if provided.\n",
    "        self.device = device if device else torch.device('cpu')  # Set the device to 'cuda' if provided, otherwise default to 'cpu'.\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_dir)  # Return the total number of patient directories.\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()  # Convert tensor index to a list if necessary.\n",
    "\n",
    "        # Get the patient directory based on the index\n",
    "        patient_dir = self.data_dir[idx]\n",
    "\n",
    "        # Load and process images from the patient directory\n",
    "        images = self.get_best_patient_images(patient_dir)\n",
    "\n",
    "        if len(images) == 0:\n",
    "            raise ValueError(f\"No images found for patient directory {patient_dir}\")\n",
    "\n",
    "        # Correct use of autocast and tensor creation\n",
    "        with torch.amp.autocast(device_type=self.device.type, dtype=torch.float16):\n",
    "            # Proper handling of tensor conversion\n",
    "            images = [\n",
    "                torch.tensor(img, dtype=torch.float32).to(self.device) if not isinstance(img, torch.Tensor) else img.to(self.device).float()\n",
    "                for img in images\n",
    "            ]\n",
    "            \n",
    "            images_tensor = torch.stack(images, dim=0).to(self.device)  # Stack images along a new dimension.\n",
    "            images_tensor_channel = torch.unsqueeze(images_tensor, 0)  # Add a channel dimension.\n",
    "\n",
    "        # Prepare the data dictionary with the image tensor\n",
    "        data = {\"im\": images_tensor_channel}\n",
    "\n",
    "        # Apply any provided transforms\n",
    "        if self.transform:\n",
    "            data = self.transform(data)  # Assuming transform takes and returns a dictionary.\n",
    "\n",
    "        return data\n",
    "\n",
    "    def get_best_patient_images(self, base_path):\n",
    "        \"\"\" \n",
    "        Process all images in the 't1_vibe_we' subfolder of each subject.\n",
    "        Sort images by Instance Number and return a sequence of a fixed length.\n",
    "        \"\"\"\n",
    "        seq_len = 32  # Desired sequence length.\n",
    "        all_images = []\n",
    "        dicom_files = [] \n",
    "        target_size = (512, 512)  # Set a fixed image shape.\n",
    "\n",
    "        for root, dirs, files in os.walk(base_path):\n",
    "            if 't1_vibe_we' in dirs:\n",
    "                t1_vibe_we_path = os.path.join(root, 't1_vibe_we')\n",
    "                \n",
    "                # Get the images in the 't1_vibe_we' sequence\n",
    "                dicom_files = []\n",
    "                for image_path in glob.glob(os.path.join(t1_vibe_we_path, '*')):\n",
    "                    try:\n",
    "                        dicom_file = pydicom.dcmread(image_path)\n",
    "                        dicom_files.append((dicom_file, image_path))\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {image_path}: {e}\")\n",
    "\n",
    "            # Sort the files by Instance Number\n",
    "            dicom_files.sort(key=lambda x: x[0].InstanceNumber)\n",
    "            \n",
    "            # Remove duplicates\n",
    "            dicom_files = self.remove_duplicates(dicom_files)\n",
    "\n",
    "            # Find the best slice\n",
    "            if dicom_files:\n",
    "                # Find the slice with the highest intensity\n",
    "                max_sum = -1\n",
    "                best_dicom_file, best_image_path = None, None\n",
    "                for dicom_file, image_path in dicom_files:\n",
    "                    image = dicom_file.pixel_array\n",
    "                    image_sum = np.sum(image)\n",
    "                    if image_sum > max_sum:\n",
    "                        max_sum = image_sum\n",
    "                        best_dicom_file, best_image_path = dicom_file, image_path\n",
    "\n",
    "                if best_dicom_file is not None:\n",
    "                    best_instance_number = best_dicom_file.InstanceNumber\n",
    "\n",
    "                    # Calculate the central slice index\n",
    "                    central_index = best_instance_number - 1  # InstanceNumber is 1-based.\n",
    "\n",
    "                    # Determine the range of slices to extract the central 5 slices\n",
    "                    start_index = max(0, central_index - 2)\n",
    "                    end_index = min(len(dicom_files), central_index + 3)\n",
    "\n",
    "                    # Extract the central 5 slices\n",
    "                    selected_slices = dicom_files[start_index:end_index]\n",
    "\n",
    "                    images = []\n",
    "                    for dicom_file, image_path in selected_slices:\n",
    "                        try:\n",
    "                            image = self.process_dicom_image(image_path, target_size=target_size)\n",
    "                            images.append(image)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing image {image_path}: {e}\")\n",
    "\n",
    "                    # Pad to the required sequence length if needed\n",
    "                    if len(images) < seq_len:\n",
    "                        # Pad with zero images of the same shape as the original images\n",
    "                        diff = seq_len - len(images)\n",
    "                        images.extend([torch.zeros(target_size, dtype=torch.float32).to(self.device) for _ in range(diff)])\n",
    "\n",
    "                    all_images.extend(images)\n",
    "\n",
    "        return all_images\n",
    "\n",
    "    def remove_duplicates(self, dicom_files):\n",
    "        \"\"\" Remove duplicate instance numbers, keeping only the slice with the highest sum of intensities. \"\"\"\n",
    "        instance_dict = defaultdict(list)\n",
    "\n",
    "        for dicom_file, image_path in dicom_files:\n",
    "            instance_number = dicom_file.InstanceNumber\n",
    "            instance_dict[instance_number].append((dicom_file, image_path))\n",
    "\n",
    "        # Compare DICOM files with the same Instance Number\n",
    "        unique_dicom_files = []\n",
    "        for instance_number, files in instance_dict.items():\n",
    "            if len(files) > 1:\n",
    "                best_slice = self.find_best_slice(files)\n",
    "                unique_dicom_files.append(best_slice)\n",
    "            else:\n",
    "                unique_dicom_files.append(files[0])\n",
    "\n",
    "        return unique_dicom_files\n",
    "\n",
    "    def find_best_slice(self, dicom_files):\n",
    "        \"\"\" Find the slice with the 'DOTAREM' ContrastBolusAgent or, as a fallback, return the first available slice. \"\"\"\n",
    "        best_slice = None\n",
    "\n",
    "        # Check for the slice with 'DOTAREM'\n",
    "        for dicom_file, image_path in dicom_files:\n",
    "            if hasattr(dicom_file, 'ContrastBolusAgent') and dicom_file.ContrastBolusAgent == 'DOTAREM':\n",
    "                best_slice = (dicom_file, image_path)\n",
    "                break  # Stop searching once we find the 'DOTAREM' slice\n",
    "\n",
    "        # Fallback: If no slice with 'DOTAREM' is found, return the first slice\n",
    "        if best_slice is None:\n",
    "            best_slice = dicom_files[0]\n",
    "\n",
    "        return best_slice\n",
    "\n",
    "    def process_dicom_image(self, path: str, resize=True, target_size=(512, 512)) -> torch.Tensor:\n",
    "        dicom_file = pydicom.dcmread(path)\n",
    "        image = torch.tensor(dicom_file.pixel_array, dtype=torch.float32).to(self.device)\n",
    "        \n",
    "        # Skip invalid images\n",
    "        if 0 in image.shape:\n",
    "            print(f\"Skipping image due to invalid shape: {image.shape}\")\n",
    "            return torch.zeros(target_size, dtype=torch.float32).to(self.device)\n",
    "        \n",
    "        # Use autocast to optimize tensor operations\n",
    "        with torch.amp.autocast(device_type=self.device.type, dtype=torch.float16):\n",
    "            # Normalize the image: Zero mean and unit variance\n",
    "            mean = image.mean()\n",
    "            std = image.std()\n",
    "            image = (image - mean) / (std + 1e-7)\n",
    "\n",
    "            # Apply 95% clipping\n",
    "            lower_bound = torch.quantile(image, 0.025)\n",
    "            upper_bound = torch.quantile(image, 0.975)\n",
    "            image = torch.clamp(image, lower_bound, upper_bound)\n",
    "\n",
    "            # Normalize again after clipping\n",
    "            mean = image.mean()\n",
    "            std = image.std()\n",
    "            image = (image - mean) / (std + 1e-7)\n",
    "\n",
    "            # Resize the image to the target size\n",
    "            if resize:\n",
    "                image = image.unsqueeze(0)  # Add channel dimension for resizing\n",
    "                image = torch.nn.functional.interpolate(image.unsqueeze(0), size=target_size, mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "        \n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the device to be used for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1  # Set the batch size to 1 for loading data one sample at a time.\n",
    "num_workers = 0  # Set the number of worker processes for data loading. 0 means data will be loaded in the main process.\n",
    "\n",
    "# Select a subset of subjects from the training set (e.g., the first 80 subjects).\n",
    "train_subset_df = train_patient_dirs[:80]\n",
    "\n",
    "# Initialize the HandScanDataset2 dataset with the selected subjects for training.\n",
    "# The dataset will apply the specified transformations and use the CUDA device for tensor operations.\n",
    "train_ds = HandScanDataset2(data_dir=train_subset_df, transform=train_transforms, device=torch.device(\"cuda\"))\n",
    "\n",
    "# Create a DataLoader for the training dataset.\n",
    "# The DataLoader will iterate over the dataset in batches, shuffling the data to ensure randomness.\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "# Select a subset of subjects from the validation set (e.g., the first 20 subjects).\n",
    "valid_subset_df = valid_patient_dirs[:20]\n",
    "\n",
    "# Initialize the HandScanDataset2 dataset with the selected subjects for validation.\n",
    "# The dataset will apply the specified transformations and use the CUDA device for tensor operations.\n",
    "train_dataset = HandScanDataset2(data_dir=valid_subset_df, transform=test_transforms, device=torch.device(\"cuda\"))\n",
    "\n",
    "# Create a DataLoader for the validation dataset.\n",
    "# The DataLoader will iterate over the dataset in batches, without shuffling, to preserve the order of data.\n",
    "test_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SwinUNETR Model Initialisation and Loading Pre-Trained Weights\n",
    "\n",
    "This section demonstrates how to initialise a SwinUNETR model with specific parameters and load pre-trained weights into the model. The weights are downloaded from a remote resource, and only the layers that match the pre-trained model are updated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where the pre-trained weights will be saved\n",
    "pre_training_weights_path = 'C:/Users/scmmw/OneDrive - University of Leeds/ssl_pretrained_weights'\n",
    "\n",
    "# Initialize the SwinUNETR model with the specific parameters to match the pre-trained model\n",
    "swin_model = SwinUNETR(\n",
    "    img_size=(32, 96, 96),  # Input image size\n",
    "    in_channels=1,  # Number of input channels (e.g., grayscale images)\n",
    "    out_channels=1,  # Number of output channels (e.g., single segmentation class)\n",
    "    feature_size=48,  # Size of features to match the pre-trained model\n",
    "    depths=(2, 2, 2, 2),  # Depths of the layers in the model\n",
    "    num_heads=(3, 6, 12, 24),  # Number of attention heads in each layer\n",
    "    spatial_dims=3,  # The model operates in 3D space\n",
    "    use_checkpoint=True  # Enables gradient checkpointing to save memory during training\n",
    ")\n",
    "swin_model = swin_model.to(torch.float32)  # Ensure the model operates in 32-bit floating-point precision\n",
    "swin_model = swin_model.to(device)  # Move the model to the specified device (e.g., GPU)\n",
    "\n",
    "# URL of the pre-trained weights to download\n",
    "resource = (\n",
    "    \"https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/ssl_pretrained_weights.pth\"\n",
    ")\n",
    "\n",
    "# Download the pre-trained weights from the given URL\n",
    "download_url(resource, pre_training_weights_path)\n",
    "\n",
    "# Load the downloaded weights into memory\n",
    "ssl_weights = torch.load(pre_training_weights_path)[\"model\"]\n",
    "\n",
    "# Copy the pre-trained weights into the SwinUNETR model, filtering layers as needed\n",
    "dst_dict, loaded, not_loaded = copy_model_state(swin_model, ssl_weights, filter_func=filter_swinunetr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze specific layers if you don't want them to be updated during fine-tuning\n",
    "for name, param in swin_model.named_parameters():\n",
    "    if \"swinViT.layers1\" in name or \"swinViT.layers2\" in name:\n",
    "        param.requires_grad = False  # Freeze these layers\n",
    "\n",
    "\n",
    "# Freeze specific layers if you don't want them to be updated during fine-tuning\n",
    "for name, param in swin_model.named_parameters():\n",
    "    if \"patch_embed\" in name:\n",
    "        param.requires_grad = False  # Freeze these layers\n",
    "\n",
    "\n",
    "for name, param in swin_model.named_parameters():\n",
    "    if 'encoder' in name and 'encoder4' not in name and 'encoder10' not in name:\n",
    "        param.requires_grad = False  # Freeze these layers\n",
    "\n",
    "# Freeze some parts of the decoder if needed\n",
    "for name, param in swin_model.named_parameters():\n",
    "     if 'decoder' in name and 'decoder4' not in name and 'decoder5' not in name:\n",
    "         param.requires_grad = False\n",
    "\n",
    "# Print which layers will be fine-tuned\n",
    "for name, param in swin_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Fine-tuning layer: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to where I will save results\n",
    "ResultsPath = '/Users/eleanorbolton/Documents/project_repo/predicting-rheumatoid-arthritis-progression-using-hand-mri-scans-from-at-risk-patients/Predicting-Rheumatoid-Arthritis-Progression-Using-Hand-MRI-Scans-from-At-Risk-Patients/predicting-rheumatoid-arthritis-progression-using-hand-mri-scans-from-at-risk-patients/src/results'\n",
    "os.makedirs(ResultsPath, exist_ok=True)\n",
    "ResultsPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function with SwinUNETR and Early Stopping\n",
    "\n",
    "This section defines a `train` function that handles the training of the SwinUNETR model using PyTorch. It includes features like mixed precision training, early stopping, and logging to TensorBoard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs to wait after the last time validation loss improved.\n",
    "            min_delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience  # The number of epochs to wait before stopping after no improvement.\n",
    "        self.min_delta = min_delta  # The minimum change in validation loss to consider as an improvement.\n",
    "        self.counter = 0  # Counts the number of epochs with no improvement.\n",
    "        self.min_validation_loss = float('inf')  # Stores the minimum validation loss encountered.\n",
    "        self.activation_count = 0  # Counts the number of times early stopping has been activated.\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        \"\"\"\n",
    "        Checks if early stopping should be triggered.\n",
    "\n",
    "        Args:\n",
    "            validation_loss (float): The current epoch's validation loss.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if early stopping criteria are met, False otherwise.\n",
    "        \"\"\"\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            # Update the minimum validation loss and reset counter if there's an improvement.\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            # Increment the counter if no improvement and check against patience.\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.activation_count += 1\n",
    "                return True  # Trigger early stopping\n",
    "        return False\n",
    "\n",
    "# Instantiate EarlyStopper\n",
    "early_stopper = EarlyStopper(patience=10, min_delta=0.001)  # Creates an EarlyStopper with specified patience and minimum delta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize paths\n",
    "log_dir = ResultsPath  # Directory where logs and TensorBoard data will be saved\n",
    "\n",
    "# Set up basic logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"swin_transformer_3d\")  # Create a logger object for the training script\n",
    "\n",
    "# Create a TensorBoard writer\n",
    "writer = SummaryWriter(log_dir=log_dir)  # Initialize TensorBoard writer with the specified log directory\n",
    "\n",
    "# Enable cuDNN auto-tuner to find the best algorithm for your hardware\n",
    "torch.backends.cudnn.benchmark = True  # This can improve performance for some models\n",
    "\n",
    "# Training function using SwinUNETR\n",
    "def train(train_loader, test_loader, max_epochs=10, learning_rate=1e-3, patience=10, model=None):\n",
    "    # Initialize the SwinUNETR model\n",
    "    logger.info('Initializing model')\n",
    "    \n",
    "    # Move the model to the specified device (e.g., GPU)\n",
    "    model.to(device)\n",
    "\n",
    "    # Define the loss function (Mean Squared Error) and optimizer (Adam)\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    early_stopper = EarlyStopper(patience=patience, min_delta=0.003)  # Early stopping with defined patience and delta\n",
    "\n",
    "    # Initialize GradScaler for mixed precision training\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    epoch_loss_values = []  # List to store the loss values for each epoch\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        epoch_start_time = time.time()  # Track the start time of the epoch\n",
    "        model.train()  # Set the model to training mode\n",
    "        epoch_loss = 0  # Initialize the loss for this epoch\n",
    "        step = 0  # Initialize the step counter\n",
    "\n",
    "        # Progress bar for the epoch\n",
    "        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{max_epochs}\", unit=\"batch\") as pbar:\n",
    "            for batch_data in train_loader:\n",
    "                batch_start_time = time.time()  # Track the start time of the batch\n",
    "                step += 1\n",
    "\n",
    "                inputs = batch_data[\"im\"].to(torch.float32).to(device)  # Move input data to the device\n",
    "                optimizer.zero_grad()  # Reset the gradients\n",
    "\n",
    "                # Use autocast for mixed precision during the forward pass\n",
    "                with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                    outputs = model(inputs)  # Forward pass through the model\n",
    "                    loss = loss_function(outputs, inputs)  # Calculate the loss\n",
    "                \n",
    "                # Scale the loss and perform the backward pass\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)  # Update model parameters\n",
    "                scaler.update()  # Update the scaler for the next iteration\n",
    "\n",
    "                epoch_loss += loss.item()  # Accumulate the loss\n",
    "\n",
    "                batch_time = time.time() - batch_start_time  # Calculate the time taken for the batch\n",
    "                pbar.set_postfix({\"Batch Time\": f\"{batch_time:.4f} sec\"})  # Update the progress bar with batch time\n",
    "                pbar.update(1)  # Move the progress bar forward\n",
    "\n",
    "        epoch_loss /= step  # Calculate the average loss for the epoch\n",
    "        epoch_loss_values.append(epoch_loss)  # Append the loss value to the list\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{max_epochs}, Loss: {epoch_loss:.4f}\")  # Log the loss for this epoch\n",
    "\n",
    "        # Validation loop with progress bar\n",
    "        total_val_loss = 0.0  # Initialize the total validation loss\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with tqdm(total=len(test_loader), desc=\"Validation\", unit=\"batch\") as pbar:\n",
    "            with torch.no_grad():  # Disable gradient computation for validation\n",
    "                for batch_data in test_loader:\n",
    "                    inputs = batch_data[\"im\"].to(torch.float32).to(device)  # Move input data to the device\n",
    "\n",
    "                    # Use autocast for mixed precision during the forward pass in validation\n",
    "                    with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                        outputs = model(inputs)  # Forward pass through the model\n",
    "                        loss_L1 = loss_function(outputs, inputs)  # Calculate the validation loss\n",
    "                        total_val_loss += loss_L1.item()  # Accumulate the validation loss\n",
    "                    \n",
    "                    pbar.update(1)  # Move the progress bar forward\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(test_loader)  # Calculate the average validation loss\n",
    "        logger.info(f\"Validation Loss: {avg_val_loss:.4f}\")  # Log the validation loss\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time  # Calculate the time taken for the epoch\n",
    "        logger.info(f\"Epoch {epoch + 1} took {epoch_time:.4f} seconds\")  # Log the epoch duration\n",
    "\n",
    "        # Early stopping check\n",
    "        if early_stopper.early_stop(avg_val_loss):\n",
    "            # Save model parameters if early stopping criteria are met for the first time\n",
    "            if early_stopper.counter == 1:\n",
    "                logger.info(f\"\\nEarly stopping criteria reached!\\nSaving model parameters to {ResultsPath}/optimal_model_weights_epoch_{epoch + 1}.pth\\n\")\n",
    "                opt_model_filepath = f\"{ResultsPath}/optimal_model_weights_epoch_{epoch + 1}.pth\"\n",
    "                torch.save(model.state_dict(), opt_model_filepath)  # Save the model's state dictionary\n",
    "\n",
    "        # Logging to TensorBoard\n",
    "        writer.add_scalar('Loss/train', epoch_loss, epoch)  # Log the training loss for TensorBoard\n",
    "        writer.add_scalar('Loss/validation', avg_val_loss, epoch)  # Log the validation loss for TensorBoard\n",
    "\n",
    "    return model, epoch_loss_values  # Return the trained model and the loss values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_curve(epoch_losses, early_stop_epoch=None, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot the training and validation loss curves and mark the early stopping point.\n",
    "\n",
    "    Args:\n",
    "        epoch_losses (list of tuples): List of tuples where each tuple contains (train_loss, val_loss) for each epoch.\n",
    "        early_stop_epoch (int, optional): Epoch where early stopping occurred. Defaults to None.\n",
    "        save_path (str, optional): Path to save the plot image. Defaults to None.\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(epoch_losses) + 1)\n",
    "    train_losses = [loss[0] for loss in epoch_losses]  # Extract training losses\n",
    "    val_losses = [loss[1] for loss in epoch_losses]  # Extract validation losses\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_losses, 'b', label='Training Loss', marker='o')\n",
    "    plt.plot(epochs, val_losses, 'g', label='Validation Loss', marker='o')\n",
    "\n",
    "    if early_stop_epoch is not None:\n",
    "        plt.axvline(x=early_stop_epoch, color='r', linestyle='--', label='Early Stopping')\n",
    "\n",
    "    plt.title('Training and Validation Loss Curves')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "max_epochs = 85  # Maximum number of training epochs\n",
    "learning_rate = 1e-2  # Learning rate for the optimizer\n",
    "patience = 10  # Number of epochs to wait for improvement before early stopping\n",
    "models = []  # List to store trained models\n",
    "epoch_losses = []  # List to store loss values for each epoch\n",
    "\n",
    "# Run the training function\n",
    "model, epoch_loss = train(train_loader, test_loader, max_epochs=max_epochs, learning_rate=learning_rate, patience=patience, model=swin_model)\n",
    "\n",
    "# Store the trained model and loss values\n",
    "models.append(model)  # Append the trained model to the models list\n",
    "epoch_losses.append(epoch_loss)  # Append the epoch loss values to the epoch_losses list\n",
    "\n",
    "# Convert the epoch loss list to a DataFrame\n",
    "epoch_loss_df = pd.DataFrame(epoch_loss, columns=['Train Loss', 'Validation Loss'])  # Create a DataFrame for the losses\n",
    "\n",
    "# Define the path to save the CSV file\n",
    "csv_path = f\"{ResultsPath}/epoch_losses.csv\"  # Path to save the loss values as a CSV\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "epoch_loss_df.to_csv(csv_path, index=False)  # Save the epoch losses to a CSV file\n",
    "logger.info(f\"Epoch losses saved to {csv_path}\")  # Log the save operation\n",
    "\n",
    "# Save the model and state dict after training\n",
    "model_path = f\"{ResultsPath}/swin_unetr_model.pth\"  # Path to save the full model\n",
    "state_dict_path = f\"{ResultsPath}/swin_unetr_state_dict.pth\"  # Path to save the model's state dictionary\n",
    "\n",
    "# Save the full model\n",
    "torch.save(model, model_path)  # Save the complete model\n",
    "\n",
    "# Save only the state dictionary (parameters) of the model\n",
    "torch.save({\"state_dict\": model.state_dict()}, state_dict_path)\n",
    "logger.info(f\"State dict saved to {state_dict_path}\")  # Log the save operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_loss_curve(epoch_losses, early_stop_epoch=None, save_path=f\"{ResultsPath}/loss_curve_Val_train.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Procedure: Evaluating the Model on the Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_slice(input_image, output_image, slice_idx, title_prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Visualize a slice from the input and output images.\n",
    "\n",
    "    Args:\n",
    "        input_image (numpy array): The input image as a numpy array.\n",
    "        output_image (numpy array): The output image as a numpy array.\n",
    "        slice_idx (int): The index of the slice to visualize.\n",
    "        title_prefix (str): Prefix for the title of the plots.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))  # Set up the figure size for the plot\n",
    "\n",
    "    # Plot the input slice\n",
    "    plt.subplot(1, 2, 1)  # Create a subplot for the input image\n",
    "    plt.imshow(input_image[slice_idx], cmap='gray')  # Display the input slice with grayscale colormap\n",
    "    plt.title(f'{title_prefix} Input Slice {slice_idx}')  # Set the title of the plot\n",
    "    plt.axis('off')  # Turn off the axis for better visualization\n",
    "\n",
    "    # Plot the output slice\n",
    "    plt.subplot(1, 2, 2)  # Create a subplot for the output image\n",
    "    plt.imshow(output_image[slice_idx], cmap='gray')  # Display the output slice with grayscale colormap\n",
    "    plt.title(f'{title_prefix} Output Slice {slice_idx}')  # Set the title of the plot\n",
    "    plt.axis('off')  # Turn off the axis for better visualization\n",
    "\n",
    "    plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_tensor(tensor):\n",
    "    \"\"\"Normalize the tensor to the [0, 1] range.\"\"\"\n",
    "    tensor_min = tensor.min()\n",
    "    tensor_max = tensor.max()\n",
    "    return (tensor - tensor_min) / (tensor_max - tensor_min + 1e-7)\n",
    "\n",
    "def clamp_tensor(tensor, min_val=0.0, max_val=1.0):\n",
    "    \"\"\"Clamp the tensor to the range [min_val, max_val].\"\"\"\n",
    "    return torch.clamp(tensor, min=min_val, max=max_val)\n",
    "\n",
    "def normalize_psnr(psnr_value, max_psnr=100.0):\n",
    "    \"\"\"Normalize the PSNR value to [0, 1] based on the max_psnr.\"\"\"\n",
    "    return min(psnr_value, max_psnr) / max_psnr\n",
    "\n",
    "def run_test(model, test_loader, loss_function, max_psnr=100.0):\n",
    "    \"\"\"Run a test on the model using a test data loader, and calculate the loss, SSIM, and PSNR metrics.\"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_test_loss = 0.0  # Initialize the total test loss\n",
    "    individual_losses = []  # List to store individual loss values\n",
    "    ssim_scores = []  # List to store SSIM scores\n",
    "    psnr_scores = []  # List to store PSNR scores\n",
    "\n",
    "    # Initialize SSIM and PSNR metrics for grayscale images (1 channel)\n",
    "    ssim_metric = SSIM(n_channels=1).to(device)\n",
    "    psnr_metric = PSNR().to(device)\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for testing\n",
    "        with tqdm(total=len(test_loader), desc=\"Testing on last 20 images\", unit=\"batch\") as pbar:\n",
    "            for batch_idx, batch_data in enumerate(test_loader):\n",
    "                inputs = batch_data[\"im\"].to(torch.float32).to(device)  # Move inputs to the device\n",
    "\n",
    "                with autocast(dtype=torch.float16):  # Use autocast for mixed precision\n",
    "                    outputs = model(inputs)  # Forward pass through the model\n",
    "                    loss = loss_function(outputs, inputs)  # Calculate the loss\n",
    "                    total_test_loss += loss.item()  # Accumulate the loss\n",
    "\n",
    "                for i in range(inputs.shape[0]):\n",
    "                    inputs_all = inputs[i].to(torch.float32).to(device)\n",
    "                    outputs_pall = outputs[i].detach().to(torch.float32).to(device)                    \n",
    "                    \n",
    "                    # Prepare tensors for PSNR calculation\n",
    "                    inputs_psnr = inputs[i].to(torch.float32).to(device)\n",
    "                    outputs_psnr = outputs[i].detach().to(torch.float32).to(device)\n",
    "\n",
    "                    # Clamp tensors to ensure all values are non-negative\n",
    "                    inputs_psnr = clamp_tensor(inputs_psnr)\n",
    "                    outputs_psnr = clamp_tensor(outputs_psnr)\n",
    "\n",
    "                    # Normalize input and output images for SSIM calculation\n",
    "                    input_image = normalize_tensor(inputs[i]).to(torch.float32).to(device)\n",
    "                    output_image = normalize_tensor(outputs[i].detach()).to(torch.float32).to(device)\n",
    "\n",
    "                    # Calculate SSIM and PSNR using piqa for grayscale images\n",
    "                    ssim_score = ssim_metric(input_image.unsqueeze(0), output_image.unsqueeze(0)).item()\n",
    "                    psnr_value = psnr_metric(inputs_psnr.unsqueeze(0), outputs_psnr.unsqueeze(0)).item()\n",
    "\n",
    "                    ssim_scores.append(ssim_score)  # Store the SSIM score\n",
    "                    psnr_scores.append(psnr_value)  # Store the PSNR score\n",
    "\n",
    "                    individual_losses.append(loss.item())  # Store the individual loss value\n",
    "\n",
    "                    # Visualize a slice of the input and output images\n",
    "                    slice_idx = input_image.shape[1] // 2\n",
    "                    visualize_slice(input_image.cpu().numpy()[0], output_image.cpu().numpy()[0], slice_idx, title_prefix=f\"Batch {batch_idx + 1}, Image {i + 1}\")\n",
    "\n",
    "                pbar.update(1)  # Update the progress bar\n",
    "\n",
    "    avg_test_loss = total_test_loss / len(test_loader)  # Calculate the average test loss\n",
    "    print(f\"Average Test Loss on the last 20 images: {avg_test_loss:.4f}\")\n",
    "\n",
    "    # Create a DataFrame to store the detailed results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Image Index': range(1, len(individual_losses) + 1),\n",
    "        'Loss': individual_losses,\n",
    "        'SSIM Score': ssim_scores,\n",
    "        'PSNR Score': psnr_scores\n",
    "    })\n",
    "\n",
    "    print(\"\\nDetailed Results for Last 20 Images:\")\n",
    "    print(results_df)  # Print the detailed results\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    csv_path = os.path.join(ResultsPath, \"test_results.csv\")\n",
    "    results_df.to_csv(csv_path, index=False)  # Save the results as a CSV file\n",
    "    print(f\"Results saved to {csv_path}\")\n",
    "\n",
    "    return avg_test_loss, results_df  # Return the average test loss and the results DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_loss_curve(epoch_losses, early_stop_epoch=None, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot the training and validation loss curves over the epochs.\n",
    "\n",
    "    Args:\n",
    "        epoch_losses (list of tuples): A list where each tuple contains (train_loss, val_loss) for each epoch.\n",
    "        early_stop_epoch (int, optional): The epoch number where early stopping occurred. Defaults to None.\n",
    "        save_path (str, optional): Path to save the plot image. Defaults to None.\n",
    "    \"\"\"\n",
    "    # Generate a range of epoch numbers\n",
    "    epochs = range(1, len(epoch_losses) + 1)\n",
    "\n",
    "    # Separate the training and validation losses from the epoch_losses tuples\n",
    "    train_losses = [loss[0] for loss in epoch_losses]\n",
    "    val_losses = [loss[1] for loss in epoch_losses]\n",
    "\n",
    "    # Set up the plot with a specified figure size\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot the training and validation loss curves\n",
    "    plt.plot(epochs, train_losses, label='Training Loss', marker='o')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss', marker='o')\n",
    "\n",
    "    # If early stopping occurred, mark the epoch on the plot\n",
    "    if early_stop_epoch is not None:\n",
    "        plt.axvline(x=early_stop_epoch, color='r', linestyle='--', label=f'Early Stopping at Epoch {early_stop_epoch}')\n",
    "\n",
    "    # Label the axes and add a title\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss per Epoch')\n",
    "    \n",
    "    # Add a legend and grid for clarity\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # If a save path is provided, save the plot as an image\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your test loader with the last 20 images from the validation set\n",
    "test_subset_df = valid_patient_dirs[-20:]  # Select the last 20 images for testing\n",
    "test_dataset = HandScanDataset2(data_dir=test_subset_df, transform=test_transforms, device=torch.device(\"cuda\"))  # Create a dataset with the selected images\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)  # Initialize the DataLoader for testing\n",
    "\n",
    "# Load the state dictionary from the saved file\n",
    "state_dict_path = r'C:\\Users\\scmmw\\OneDrive - University of Leeds\\Masters - 23-24\\Project\\results\\swin_unetr_state_dict.pth'  # Path to the saved state dictionary\n",
    "state_dict = torch.load(state_dict_path)  # Load the state dictionary from the file\n",
    "\n",
    "swin_model.load_state_dict(state_dict['state_dict'])  # Load the state dictionary into the SwinUNETR model\n",
    "\n",
    "# Run the test and get the loss and similarity results\n",
    "avg_test_loss, results_df = run_test(swin_model, test_loader, nn.MSELoss())  # Run the test and obtain the average loss and results DataFrame\n",
    "\n",
    "import os  # Import the os module for file path handling\n",
    "\n",
    "# Define the path where you want to save the CSV file\n",
    "csv_path = os.path.join(ResultsPath, \"test_results.csv\")  # Set the path for saving the test results CSV\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(csv_path, index=False)  # Save the test results to the CSV file without the index column\n",
    "\n",
    "print(f\"Results saved to {csv_path}\")  # Print a message indicating where the results were saved\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

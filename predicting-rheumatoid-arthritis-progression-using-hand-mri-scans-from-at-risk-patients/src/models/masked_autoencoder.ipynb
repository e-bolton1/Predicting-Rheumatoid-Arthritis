{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eleanorbolton/Library/CloudStorage/OneDrive-UniversityofLeeds/CCP_MRI_image_subset\n",
      "{'CCP_120': 1, 'CCP_117': 0, 'CCP_73': 0, 'CCP_386': 1, 'CCP_644': 1, 'CCP_NG_166': 0, 'CCP_NG_42': 1, 'CCP_138': 0, 'CCP_874': 0, 'CCP_907': 1, 'CCP_NG_137': 1, 'CCP_647': 1, 'CCP_262': 0, 'CCP_541': 0, 'CCP_89': 0, 'CCP_202': 0, 'CCP_NG_56': 0, 'CCP_821': 1, 'CCP_66': 0, 'CCP_471': 0, 'CCP_34': 0, 'CCP_181': 1, 'CCP_557': 1, 'CCP_416': 0, 'CCP_NG_207': 0, 'CCP_568': 0, 'CCP_753': 0, 'CCP_NG_181': 0, 'CCP_81': 0, 'CCP_415': 1, 'CCP_NG_8': 1, 'CCP_283': 1, 'CCP_906': 0, 'CCP_968': 0, 'CCP_664': 0, 'CCP_736': 0, 'CCP_355': 0, 'CCP_NG_104': 1, 'CCP_247': 1, 'CCP_NG_188': 1, 'CCP_976': 0, 'CCP_NG_214': 0, 'CCP_824': 1, 'CCP_62': 0, 'CCP_NG_36': 0, 'CCP_802': 0, 'CCP_NG_172': 0, 'CCP_873': 0, 'CCP_207': 0, 'CCP_167': 1, 'CCP_944': 1, 'CCP_133': 1, 'CCP_NG_60': 0, 'CCP_1000': 0, 'CCP_252': 1, 'CCP_672': 0, 'CCP_531': 0, 'CCP_NG_175': 1, 'CCP_NG_107': 1, 'CCP_53': 0, 'CCP_NG_106': 1, 'CCP_105': 0, 'CCP_507': 1, 'CCP_405': 0, 'CCP_172': 1, 'CCP_901': 1, 'CCP_212': 1, 'CCP_485': 0, 'CCP_185': 0, 'CCP_422': 0, 'CCP_245': 1, 'CCP_NG_86': 0, 'CCP_263': 0, 'CCP_NG_150': 0, 'CCP_354': 1, 'CCP_307': 0, 'CCP_668': 1, 'CCP_174': 0, 'CCP_NG_16': 0, 'CCP_NG_49': 0, 'CCP_505': 0, 'CCP_849': 1, 'CCP_573': 0, 'CCP_643': 0, 'CCP_47': 0, 'CCP_619': 1, 'CCP_NG_52': 0, 'CCP_879': 1, 'CCP_102': 1, 'CCP_752': 0, 'CCP_NG_116': 0, 'CCP_NG_85': 1, 'CCP_457': 1, 'CCP_NG_79': 1, 'CCP_229': 0, 'CCP_199': 0, 'CCP_NG_147': 1, 'CCP_828': 0, 'CCP_131': 1, 'CCP_NG_144': 0, 'CCP_794': 1, 'CCP_NG_178': 0, 'CCP_783': 1, 'CCP_100': 0, 'CCP_330': 1, 'CCP_859': 0, 'CCP_657': 1, 'CCP_393': 0, 'CCP_NG_102': 1, 'CCP_635': 1, 'CCP_426': 0, 'CCP_NG_9': 0, 'CCP_520': 0, 'CCP_780': 1, 'CCP_894': 0, 'CCP_412': 0, 'CCP_50': 1, 'CCP_NG_96': 0, 'CCP_NG_160': 1, 'CCP_638': 0, 'CCP_124': 1, 'CCP_864': 0, 'CCP_103': 1, 'CCP_NG_97': 1, 'CCP_321': 0, 'CCP_228': 1, 'CCP_631': 1, 'CCP_666': 0, 'CCP_71': 0, 'CCP_319': 0, 'CCP_616': 1, 'CCP_52': 0, 'CCP_191': 1, 'CCP_NG_68': 0, 'CCP_NG_140': 1, 'CCP_44': 1, 'CCP_827': 0, 'CCP_830': 1, 'CCP_419': 0, 'CCP_389': 0, 'CCP_909': 1, 'CCP_414': 1, 'CCP_884': 0, 'CCP_NG_169': 0, 'CCP_78': 1, 'CCP_523': 0, 'CCP_NG_117': 1, 'CCP_NG_177': 1, 'CCP_266': 0, 'CCP_28': 1, 'CCP_NG_174': 1, 'CCP_516': 0, 'CCP_646': 0, 'CCP_NG_29': 0, 'CCP_NG_59': 1, 'CCP_169': 1, 'CCP_695': 1, 'CCP_290': 1, 'CCP_NG_17': 1, 'CCP_NG_185': 1, 'CCP_352': 0, 'CCP_87': 0, 'CCP_304': 0, 'CCP_57': 1, 'CCP_420': 1, 'CCP_107': 0, 'CCP_82': 1, 'CCP_1001': 1, 'CCP_65': 0, 'CCP_NG_54': 1, 'CCP_1008': 1, 'CCP_519': 1}\n",
      "{'CCP_947': 1, 'CCP_402': 1, 'CCP_1018': 0, 'CCP_NG_100': 0, 'CCP_180': 0, 'CCP_NG_1': 0, 'CCP_565': 1, 'CCP_612': 0, 'CCP_NG_23': 1, 'CCP_153': 0, 'CCP_804': 0, 'CCP_NG_67': 0, 'CCP_371': 1, 'CCP_NG_77': 0, 'CCP_511': 1, 'CCP_444': 1, 'CCP_70': 1, 'CCP_NG_229': 0, 'CCP_279': 1, 'CCP_239': 0, 'CCP_56': 1, 'CCP_NG_143': 0, 'CCP_829': 0, 'CCP_NG_197': 1, 'CCP_NG_113': 0, 'CCP_168': 0, 'CCP_43': 0, 'CCP_380': 1, 'CCP_NG_122': 0, 'CCP_369': 1, 'CCP_94': 0, 'CCP_46': 0, 'CCP_214': 1, 'CCP_954': 0, 'CCP_510': 0, 'CCP_113': 1, 'CCP_969': 1, 'CCP_45': 1, 'CCP_NG_39': 0, 'CCP_508': 0, 'CCP_823': 1, 'CCP_349': 0, 'CCP_598': 1, 'CCP_846': 1}\n",
      "Best instance number: 55\n",
      "Patient ID: CCP_120, Image shape: (96, 384, 512)\n",
      "Sample 0: Image shape: torch.Size([1, 96, 96, 96]), Label: 1\n",
      "Best instance number: 77\n",
      "Patient ID: CCP_117, Image shape: (96, 384, 512)\n",
      "Sample 1: Image shape: torch.Size([1, 96, 96, 96]), Label: 0\n",
      "Best instance number: 84\n",
      "Patient ID: CCP_73, Image shape: (96, 384, 512)\n",
      "Sample 2: Image shape: torch.Size([1, 96, 96, 96]), Label: 0\n"
     ]
    }
   ],
   "source": [
    "# import pre_processing \n",
    "from pre_processing import HandScanDataset2, transform, validation_transform, train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(ConvBlock3D, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder3D(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Encoder3D, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            ConvBlock3D(in_channels, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "            ConvBlock3D(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "            ConvBlock3D(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "            ConvBlock3D(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder3D(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Decoder3D, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(in_channels, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose3d(32, 1, kernel_size=2, stride=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedAutoencoder3D(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(MaskedAutoencoder3D, self).__init__()\n",
    "        self.encoder = Encoder3D(in_channels)\n",
    "        self.decoder = Decoder3D(256)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x_masked = x * mask\n",
    "        encoded = self.encoder(x_masked)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(shape, mask_ratio=0.7):\n",
    "    mask = np.ones(shape)\n",
    "    num_elements = shape[1] * shape[2] * shape[3]\n",
    "    num_masked = int(mask_ratio * num_elements)\n",
    "    indices = np.random.choice(num_elements, num_masked, replace=False)\n",
    "    mask.reshape(-1)[indices] = 0\n",
    "    return torch.tensor(mask, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom loss function\n",
    "def custom_loss(output, target, alpha=0.8):\n",
    "    mse_loss = nn.MSELoss()\n",
    "    pixel_loss = mse_loss(output, target)\n",
    "    freq_loss = mse_loss(torch.fft.fftn(output), torch.fft.fftn(target))\n",
    "    return alpha * pixel_loss + (1 - alpha) * freq_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mae(model, train_loader, val_loader, num_epochs, learning_rate):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for images, _ in train_loader:\n",
    "            mask = create_mask(images.shape)\n",
    "            outputs = model(images, mask)\n",
    "            loss = custom_loss(outputs, images)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, _ in val_loader:\n",
    "                mask = create_mask(images.shape)\n",
    "                outputs = model(images, mask)\n",
    "                loss = custom_loss(outputs, images)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
